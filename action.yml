name: "WD201 Action"
description: 'Handles checkout, testing, and grading for WD201 submissions'
author: 'pupilfirst'

inputs:
  level_name:
    description: "Name of level e.g., l1, l2, etc."
  globs:
    description: "This contains the list of files that will checked during repo verification"
  copy_commands:
    description: "Shell commands to execute that copy the required files for running tests"
  report_file_path:
    description: "It contains the path to report.json file, ex: submission/someFolder/report.json"
  test_failure_feedback:
    description: "It contains test failure feedback for l1 "
  submissionUrl:
    description: "It contains the url of live application "

runs:
  using: "composite"
  steps:
    # checkout student's repository and verify its structure
    - uses: actions/checkout@v2
    - name: Checkout student repo and verify its structure
      id: check-student-repo
      uses: pupilfirst/check-repo-action@v1
      with:
        repoPath: submission
        globs: ${{ inputs.globs }}

    # Report to LMS tests are in progress
    - name: Report to LMS that tests in progress
      if: ${{ steps.check-student-repo.outputs.result == 'success' }}
      uses: pupilfirst/report-action@v1
      with:
        status: "in_progress"
        description: "Automated tests are in progress."

    # Checkout the wd201-tests repo
    - name: Check out the solutions repo
      if: ${{ steps.check-student-repo.outputs.result == 'success' }}
      id: checkout-solutions-repo
      uses: actions/checkout@v2
      with:
        repository: pupilfirst/wd201-tests
        path: solution

    # Copy submission/test files to solution/student's repo
    - name: Copy test files to submission repo
      if: steps.checkout-solutions-repo.outcome == 'success'
      id: copy-submission-files
      continue-on-error: true
      run: ${{ inputs.copy_commands }}
      shell: bash

    # Generate output
    - name: Setup and Test Submission
      if: ${{ steps.check-student-repo.outputs.result == 'success' || steps.copy-submission-files.outcome == 'success' }}
      id: check-submission-output
      continue-on-error: true
      run: |
        case ${{ inputs.level_name }} in
          "l1")
            node submission/hello-world/index.js > output.txt
            ;;
          "l3")
            cd solution/l3
            node index.js &> output.txt
            ;;
        esac
      shell: bash

    # run the tests
    - name: Setup and Test Submission
      if: ${{ steps.checkout-solutions-repo.outcome == 'success' || steps.copy-submission-files.outcome == 'success' }}
      id: run-test
      continue-on-error: true
      run: |
        # Function to handle common tasks
        run_tests() {
          cd "$1"         # Change to the directory specified by the first argument
          npm install     # Install npm packages
          $2              # Execute the command specified by the second argument
        }

        # Conditional logic to run tests based on the level
        case ${{ inputs.level_name }} in
          "l2")
            run_tests "submission/http-server" "npm run test"
            ;;
          "l3")
            cd solution/l3
            node test.js
            ;;
          "l4" | "l5" | "l6")
            run_tests "solution/${{ inputs.level_name }}" "npm run test"
            ;;
          "l9" | "l10")
            run_tests "solution/${{ inputs.level_name }}" "npm install cypress cypress-json-results && npx cypress run --env STUDENT_SUBMISSION_URL='http://localhost:3000/'"
            ;;
        esac
      shell: bash


    # Cypress for l7 & l8
    - name: Cypress run with env
      if: ${{(inputs.level_name == 'l7' || inputs.level_name == 'l8') && steps.checkout-solutions-repo.outcome == 'success'}}
      uses: cypress-io/github-action@v6
      continue-on-error: true
      with:
        wait-on: ${{inputs.submissionUrl}}
        wait-on-timeout: 540
        project: ./solution/${{inputs.level_name}}
        env: STUDENT_SUBMISSION_URL=${{inputs.submissionUrl}}

    # Run the app for l9 and l10
    - name: Run the app
      if:  ${{ (inputs.level_name == 'l9' || inputs.level_name == 'l10') && steps.copy-submission-files.outcome == 'success' }}
      id: run-app
      run: |
        cd solution/${{inputs.level_name}}
        npm install
        npx sequelize-cli db:drop
        npx sequelize-cli db:create
        npx sequelize-cli db:migrate
        PORT=3000 npm start &
        sleep 5
      shell: bash

    # Report failure
    - name: Report failure if tests fails
      if: steps.check-submission-output.outcome == 'failure'
      uses: pupilfirst/grade-action@v1
      with:
        fail_submission: true
        feedback: ${{inputs.test_failure_feedback}}

    # Report Success
    - name: Generate feedback Report if all tests passed
      id: generate-report
      if: ${{steps.check-submission-output.outcome == 'success' && steps.checkout-solutions-repo.outcome == 'success'}}
      continue-on-error: true
      run: |
        case ${{ inputs.level_name }} in
          "l1")
            echo "const fs = require(\"fs\");

            function checkValidString(input) {
              return input.toLowerCase().indexOf(\"hello\") > -1;
            }

            fs.readFile(\"output.txt\", \"utf8\", (err, data) => {
              if (err) {
                throw err;
              } else {
                let passed = checkValidString(data);
                let reportFile = \"./report.json\";
                let feedback = passed
                  ? \"Good work! It looks like your code prints the output according to the specification.\"
                  : \"Uh oh! It looks like you've missed some parts of the assignment! Please ensure that your `index.js` script outputs the expected message mentioned in the assignment and try again.\";
                let report = {
                  version: 0,
                  grade: passed ? \"accept\" : \"reject\",
                  status: passed ? \"success\" : \"failure\",
                  feedback: feedback,
                };
                fs.writeFileSync(reportFile, JSON.stringify(report));
              }
            });" | node
            ;;
          "l2")
            cd submission/http-server && node generateReportFromResults.js
            ;;
          "l4")
            cd solution/l4 && node generateReportFromResults.js
            ;;
          "l5")
            cd solution/l5 && node generateReportFromResults.js
            ;;
          "l6")
            cd solution/l6 && node generateReportFromResults.js
            ;;
          # ... Add cases for other levels (L3 to L11)
          "l7")
            cd solution/l7 && node generateReportFromResults.js
            ;;
          "l8")
            cd solution/l8 && node generateReportFromResults.js
            ;;
          "l9")
            cd solution/l9 && node generateReportFromResults.js
            ;;
          "l10")
            cd solution/l10 && node generateReportFromResults.js
            ;;
          # ... Add cases for other levels (L3 to L11)
        esac
      shell: bash

    # Grade submissions
    - name: Grade the submission based on test results
      uses: pupilfirst/grade-action@v1
      if: steps.generate-report.outcome == 'success'
      with:
        report_file_path: ${{ inputs.report_file_path }}

    # Report outcome of tests to the LMS
    - name: Report outcome of tests to LMS
      uses: pupilfirst/report-action@v1
      if: steps.generate-report.outcome == 'success'
      id: report-test-results
      with:
        report_file_path: ${{ inputs.report_file_path }}

    # Report error in testing to LMS
    - name: Report error in testing to LMS
      uses: pupilfirst/report-action@v1
      if: ${{ steps.checkout-solutions-repo.outcome == 'success' && steps.report-test-results.outcome == 'skipped' }}
      with:
        status: "error"
        description: "Automated tests could not be run successfully"
