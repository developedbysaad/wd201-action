name: "WD201 Action"
description: 'Handles checkout, testing, and grading for WD201 submissions'
author: 'pupilfirst'

inputs:
  level_name:
    description: "Name of level e.g., L1, L2, etc."
  globs:
    description: "This contains the list of files that will checked during repo verification,"
  report_file_path:
    description: "It contains the path to report.json file, ex: submission/someFolder/report.json"
  test_failure_feedback:
    description: "It contains test failure feedback"

runs:
  using: "composite"
  steps:
    # checkout student's repository and verify its structure
    - uses: actions/checkout@v2
    - name: Checkout student repo and verify its structure
      id: check-student-repo
      uses: pupilfirst/check-repo-action@v1
      with:
        repoPath: submission
        globs: ${{ inputs.globs }}

    # Report to LMS tests are in progress
    - name: Report to LMS tests in progress
      if: ${{ steps.check-student-repo.outputs.result == 'success' }}
      uses: pupilfirst/report-action@v1
      with:
        status: "in_progress"
        description: "Automated tests are in progress."

    # Checkout the wd201-tests repo
    - name: Check out the solutions repo
      if: ${{ steps.check-student-repo.outputs.result == 'success' }}
      id: checkout-solutions-repo
      uses: actions/checkout@v2
      with:
        repository: pupilfirst/wd201-tests
        path: solution

    # Copy submission/test files to solution/student's repo
    - name: Copy test files to submission repo
      if: steps.checkout-solutions-repo.outcome == 'success'
      id: copy-submission-files
      continue-on-error: true
      run: |
        # Conditional logic to copy necessary files based on the level
        case ${{ inputs.level_name }} in
          "L2")
            cp -r solution/l2/cypress submission/http-server
            cp solution/l2/cypress.config.js submission/http-server
            cp solution/l2/generateReportFromResults.js submission/http-server
            cp solution/l2/package-lock.json submission/http-server
            cp solution/l2/package.json submission/http-server
            ;;
          "L3")
            cp submission/todo-cli/todo.js solution/l3/index.js
            ;;
          "L4")
            rm -rf solution/l4/__tests__
            cp -r submission/todo-cli/__tests__ solution/l4
            cp submission/todo-cli/todo.js solution/l4/todo.js
            cp submission/todo-cli/__tests__/todo.js solution/l4/__tests__/todoFailure.js
            sed -i 's/("..\/todo")/("..\/todoFailure")/g' solution/l4/__tests__/todoFailure.js
            sed -i "s/('..\/todo')/('..\/todoFailure')/g" solution/l4/__tests__/todoFailure.js
            ;;
          "L5")
            cp submission/todo-cli/models/todo.js solution/l5/models/todo.js
            ;;
          "L6")
            rm -rf solution/models
            cp -r solution/helpers/generateReportFromResults.js solution/l6/generateReportFromResults.js
            cp -r submission/todo-app/models/ solution/l6/
            cp submission/todo-app/app.js solution/l6/app.js
            ;;
        esac
      shell: bash

    # Generate output
    - name: Setup and Test Submission
      if: ${{ steps.check-student-repo.outputs.result == 'success' || steps.copy-submission-files.outcome == 'success' }}
      id: check-submission-output
      continue-on-error: true
      run: |
        case ${{ inputs.level_name }} in
          "L1")
            node submission/hello-world/index.js > output.txt
            ;;
          "L3")
            cd solution/l3
            node index.js &> output.txt
            ;;
          # ... Add cases for other levels (L3 to L11)
        esac
      shell: bash

    # run the tests
    - name: Setup and Test Submission
      if: ${{steps.checkout-solutions-repo.outcome == 'success' || steps.copy-submission-files.outcome == 'success' }}
      id: run-test
      continue-on-error: true
      run: |
        # Conditional logic to run tests based on the level
        case ${{ inputs.level_name }} in
          "L2")
            cd submission/http-server
            npm install
            npm run test
            ;;
          "L3")
            cd solution/l3
            node test.js
            ;;
          "L4")
            cd solution/l4
            npm install
            npm run test
            ;;
          "L5")
            cd solution/l5
            npm install
            npm run test
            ;;
          "L6")
            cd solution/l6
            npm install
            npm run test
            ;;
        esac
      shell: bash

    # Report failure
    - name: Report failure if tests fails
      if: steps.check-submission-output.outcome == 'failure'
      uses: pupilfirst/grade-action@v1
      with:
        fail_submission: true
        feedback: ${{inputs.test_failure_feedback}}

    # Report Success
    - name: Generate feedback Report if all tests passed
      id: generate-report
      if: ${{steps.check-submission-output.outcome == 'success' && steps.checkout-solutions-repo.outcome == 'success'}}
      continue-on-error: true
      run: |
        case ${{ inputs.level_name }} in
          "L1")
            echo "const fs = require(\"fs\");

            function checkValidString(input) {
              return input.toLowerCase().indexOf(\"hello\") > -1;
            }

            fs.readFile(\"output.txt\", \"utf8\", (err, data) => {
              if (err) {
                throw err;
              } else {
                let passed = checkValidString(data);
                let reportFile = \"./report.json\";
                let feedback = passed
                  ? \"Good work! It looks like your code prints the output according to the specification.\"
                  : \"Uh oh! It looks like you've missed some parts of the assignment! Please ensure that your `index.js` script outputs the expected message mentioned in the assignment and try again.\";
                let report = {
                  version: 0,
                  grade: passed ? \"accept\" : \"reject\",
                  status: passed ? \"success\" : \"failure\",
                  feedback: feedback,
                };
                fs.writeFileSync(reportFile, JSON.stringify(report));
              }
            });" | node
            ;;
          "L2")
            cd submission/http-server && node generateReportFromResults.js
            ;;
          "L4")
            cd solution/l4 && node generateReportFromResults.js
            ;;
          "L5")
            cd solution/l5 && node generateReportFromResults.js
            ;;
          "L6")
            cd solution/l6 && node generateReportFromResults.js
            ;;
          # ... Add cases for other levels (L3 to L11)
        esac
      shell: bash

    # Grade submissions
    - name: Grade the submission based on test results
      uses: pupilfirst/grade-action@v1
      if: steps.generate-report.outcome == 'success'
      with:
        report_file_path: ${{ inputs.report_file_path }}

    # Report outcome of tests to the LMS
    - name: Report outcome of tests to LMS
      uses: pupilfirst/report-action@v1
      if: steps.generate-report.outcome == 'success'
      id: report-test-results
      with:
        report_file_path: ${{ inputs.report_file_path }}

    # Report error in testing to LMS
    - name: Report error in testing to LMS
      uses: pupilfirst/report-action@v1
      if: ${{ steps.checkout-solutions-repo.outcome == 'success' && steps.report-test-results.outcome == 'skipped' }}
      with:
        status: "error"
        description: "Automated tests could not be run successfully"
